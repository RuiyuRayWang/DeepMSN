{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33d484e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ## Scratch\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# from torch.utils.data import DataLoader\n",
    "# from datasets.topic_datasets import TopicDataset\n",
    "# from models.deepflybrain import DeepFlyBrain\n",
    "# import numpy as np\n",
    "\n",
    "# device = torch.device(f'cuda:3')  # Use same device as training\n",
    "# print(f\"Using {device} device\")\n",
    "\n",
    "# model = DeepFlyBrain().to(device)\n",
    "\n",
    "# checkpoint_path = './checkpoints/dfb_2025-05-28_14-46-48/model_epoch_100.pth'\n",
    "# checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "# model.load_state_dict(checkpoint)\n",
    "\n",
    "# dataset = TopicDataset(\n",
    "#     genome='data/resources/mm10.fa',\n",
    "#     region_topic_bed='data/Furlanis_Topics_top_3k/regions_and_topics_sorted.bed',\n",
    "#     transform=None,\n",
    "#     target_transform=None\n",
    "# )\n",
    "# dataloader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=1)\n",
    "\n",
    "# model.eval()\n",
    "\n",
    "# all_probs = []\n",
    "# all_targets = []\n",
    "# all_predictions = []\n",
    "\n",
    "# total_samples = 0\n",
    "# exact_matches = 0\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for batch_idx, batch in enumerate(dataloader):\n",
    "#         X, y = batch['sequence'], batch['label']\n",
    "#         X, y = X.to(device), y.to(device)\n",
    "#         y = y.float()\n",
    "        \n",
    "#         # Make predictions\n",
    "#         pred_logits = model(X)\n",
    "#         pred_probs = torch.sigmoid(pred_logits)\n",
    "        \n",
    "#         all_probs.append(pred_probs.cpu())\n",
    "#         all_targets.append(y.cpu())\n",
    "        \n",
    "#         # Test multiple thresholds\n",
    "#         for threshold in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "#             pred_binary = (pred_probs > threshold).float()\n",
    "            \n",
    "#             if threshold == 0.5:  # Store predictions at default threshold\n",
    "#                 all_predictions.append(pred_binary.cpu())\n",
    "            \n",
    "#             # Calculate exact match for this threshold\n",
    "#             exact_match = ((pred_binary == y).sum(dim=1) == y.shape[1]).float().sum().item()\n",
    "            \n",
    "#             if batch_idx == 0:  # Print for first batch only\n",
    "#                 print(f\"Threshold {threshold}: {exact_match}/{y.shape[0]} exact matches\")\n",
    "        \n",
    "#         total_samples += y.shape[0]\n",
    "        \n",
    "#         # Calculate exact matches at 0.5 threshold\n",
    "#         pred_binary_05 = (pred_probs > 0.5).float()\n",
    "#         exact_matches += ((pred_binary_05 == y).sum(dim=1) == y.shape[1]).float().sum().item()\n",
    "\n",
    "# # Concatenate all results\n",
    "# all_probs = torch.cat(all_probs, dim=0)\n",
    "# all_targets = torch.cat(all_targets, dim=0)\n",
    "# all_predictions = torch.cat(all_predictions, dim=0)\n",
    "\n",
    "# # Calculate comprehensive metrics\n",
    "# results = {}\n",
    "\n",
    "# # Test different thresholds\n",
    "# for threshold in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "#     pred_binary = (all_probs > threshold).float()\n",
    "    \n",
    "#     # Exact match accuracy\n",
    "#     exact_match = ((pred_binary == all_targets).sum(dim=1) == all_targets.shape[1]).float().mean()\n",
    "    \n",
    "#     # Hamming accuracy (per-label accuracy)\n",
    "#     hamming_acc = (pred_binary == all_targets).float().mean()\n",
    "    \n",
    "#     # Jaccard accuracy (intersection over union)\n",
    "#     intersection = (pred_binary * all_targets).sum(dim=1)\n",
    "#     union = ((pred_binary + all_targets) > 0).float().sum(dim=1)\n",
    "#     jaccard_acc = (intersection / (union + 1e-7)).mean()\n",
    "    \n",
    "#     # Count predictions vs targets\n",
    "#     pred_count = pred_binary.sum().item()\n",
    "#     target_count = all_targets.sum().item()\n",
    "    \n",
    "#     # Per-class F1 scores\n",
    "#     tp = (pred_binary * all_targets).sum(dim=0)\n",
    "#     fp = (pred_binary * (1 - all_targets)).sum(dim=0)\n",
    "#     fn = ((1 - pred_binary) * all_targets).sum(dim=0)\n",
    "    \n",
    "#     precision = tp / (tp + fp + 1e-7)\n",
    "#     recall = tp / (tp + fn + 1e-7)\n",
    "#     f1_per_class = 2 * precision * recall / (precision + recall + 1e-7)\n",
    "#     avg_f1 = f1_per_class.mean()\n",
    "    \n",
    "#     results[threshold] = {\n",
    "#         'exact_match': exact_match.item(),\n",
    "#         'hamming_acc': hamming_acc.item(),\n",
    "#         'jaccard_acc': jaccard_acc.item(),\n",
    "#         'avg_f1': avg_f1.item(),\n",
    "#         'pred_count': pred_count,\n",
    "#         'target_count': target_count,\n",
    "#         'pred_ratio': pred_count / target_count if target_count > 0 else 0\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa3c9a6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets.topic_datasets import TopicDataset\n",
    "from models.deepflybrain import DeepFlyBrain\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(f'cuda:3')  # Use same device as training\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "def load_model(checkpoint_path, device):\n",
    "    \"\"\"Load model from checkpoint\"\"\"\n",
    "    model = DeepFlyBrain().to(device)\n",
    "    \n",
    "    # Load the state dict\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    \n",
    "    # Set to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"Model loaded from: {checkpoint_path}\")\n",
    "    return model\n",
    "\n",
    "def test_single_sample(model, sample, device):\n",
    "    \"\"\"Test model on a single sample\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Get sequence and label\n",
    "        sequence = sample['sequence'].unsqueeze(0).to(device)  # Add batch dimension\n",
    "        true_label = sample['label'].unsqueeze(0).to(device)\n",
    "        \n",
    "        # Make prediction\n",
    "        pred_logits = model(sequence)\n",
    "        pred_probs = torch.sigmoid(pred_logits)\n",
    "        \n",
    "        # Apply threshold\n",
    "        pred_binary = (pred_probs > 0.5).float()\n",
    "        \n",
    "        return {\n",
    "            'true_label': true_label.cpu().numpy()[0],\n",
    "            'pred_probs': pred_probs.cpu().numpy()[0],\n",
    "            'pred_binary': pred_binary.cpu().numpy()[0],\n",
    "            'sequence_shape': sequence.shape\n",
    "        }\n",
    "\n",
    "def test_model_comprehensive(model, test_dataloader, device):\n",
    "    \"\"\"Comprehensive model testing\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_probs = []\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    total_samples = 0\n",
    "    exact_matches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataloader):\n",
    "            X, y = batch['sequence'], batch['label']\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y = y.float()\n",
    "            \n",
    "            # Make predictions\n",
    "            pred_logits = model(X)\n",
    "            pred_probs = torch.sigmoid(pred_logits)\n",
    "            \n",
    "            all_probs.append(pred_probs.cpu())\n",
    "            all_targets.append(y.cpu())\n",
    "            \n",
    "            # Test multiple thresholds\n",
    "            for threshold in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "                pred_binary = (pred_probs > threshold).float()\n",
    "                \n",
    "                if threshold == 0.5:  # Store predictions at default threshold\n",
    "                    all_predictions.append(pred_binary.cpu())\n",
    "                \n",
    "                # Calculate exact match for this threshold\n",
    "                exact_match = ((pred_binary == y).sum(dim=1) == y.shape[1]).float().sum().item()\n",
    "                \n",
    "                if batch_idx == 0:  # Print for first batch only\n",
    "                    print(f\"Threshold {threshold}: {exact_match}/{y.shape[0]} exact matches\")\n",
    "            \n",
    "            total_samples += y.shape[0]\n",
    "            \n",
    "            # Calculate exact matches at 0.5 threshold\n",
    "            pred_binary_05 = (pred_probs > 0.5).float()\n",
    "            exact_matches += ((pred_binary_05 == y).sum(dim=1) == y.shape[1]).float().sum().item()\n",
    "    \n",
    "    # Concatenate all results\n",
    "    all_probs = torch.cat(all_probs, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "    all_predictions = torch.cat(all_predictions, dim=0)\n",
    "    \n",
    "    # Calculate comprehensive metrics\n",
    "    results = {}\n",
    "    \n",
    "    # Test different thresholds\n",
    "    for threshold in [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]:\n",
    "        pred_binary = (all_probs > threshold).float()\n",
    "        \n",
    "        # Exact match accuracy\n",
    "        exact_match = ((pred_binary == all_targets).sum(dim=1) == all_targets.shape[1]).float().mean()\n",
    "        \n",
    "        # Hamming accuracy (per-label accuracy)\n",
    "        hamming_acc = (pred_binary == all_targets).float().mean()\n",
    "        \n",
    "        # Jaccard accuracy (intersection over union)\n",
    "        intersection = (pred_binary * all_targets).sum(dim=1)\n",
    "        union = ((pred_binary + all_targets) > 0).float().sum(dim=1)\n",
    "        jaccard_acc = (intersection / (union + 1e-7)).mean()\n",
    "        \n",
    "        # Count predictions vs targets\n",
    "        pred_count = pred_binary.sum().item()\n",
    "        target_count = all_targets.sum().item()\n",
    "        \n",
    "        # Per-class F1 scores\n",
    "        tp = (pred_binary * all_targets).sum(dim=0)\n",
    "        fp = (pred_binary * (1 - all_targets)).sum(dim=0)\n",
    "        fn = ((1 - pred_binary) * all_targets).sum(dim=0)\n",
    "        \n",
    "        precision = tp / (tp + fp + 1e-7)\n",
    "        recall = tp / (tp + fn + 1e-7)\n",
    "        f1_per_class = 2 * precision * recall / (precision + recall + 1e-7)\n",
    "        avg_f1 = f1_per_class.mean()\n",
    "        \n",
    "        results[threshold] = {\n",
    "            'exact_match': exact_match.item(),\n",
    "            'hamming_acc': hamming_acc.item(),\n",
    "            'jaccard_acc': jaccard_acc.item(),\n",
    "            'avg_f1': avg_f1.item(),\n",
    "            'pred_count': pred_count,\n",
    "            'target_count': target_count,\n",
    "            'pred_ratio': pred_count / target_count if target_count > 0 else 0\n",
    "        }\n",
    "    \n",
    "    return results, all_probs, all_targets, all_predictions\n",
    "\n",
    "def analyze_predictions(all_probs, all_targets, threshold=0.5):\n",
    "    \"\"\"Analyze prediction patterns\"\"\"\n",
    "    pred_binary = (all_probs > threshold).float()\n",
    "    \n",
    "    print(f\"\\n=== PREDICTION ANALYSIS (threshold={threshold}) ===\")\n",
    "    \n",
    "    # Overall statistics\n",
    "    print(f\"Total samples: {all_targets.shape[0]}\")\n",
    "    print(f\"Total classes: {all_targets.shape[1]}\")\n",
    "    print(f\"Total target positives: {all_targets.sum().item():.0f}\")\n",
    "    print(f\"Total predicted positives: {pred_binary.sum().item():.0f}\")\n",
    "    print(f\"Prediction ratio: {pred_binary.sum().item() / all_targets.sum().item():.2f}\")\n",
    "    \n",
    "    # Per-class analysis\n",
    "    print(f\"\\nPer-class analysis:\")\n",
    "    for class_idx in range(all_targets.shape[1]):\n",
    "        target_class = all_targets[:, class_idx]\n",
    "        pred_class = pred_binary[:, class_idx]\n",
    "        \n",
    "        true_positives = (pred_class * target_class).sum().item()\n",
    "        false_positives = (pred_class * (1 - target_class)).sum().item()\n",
    "        false_negatives = ((1 - pred_class) * target_class).sum().item()\n",
    "        true_negatives = ((1 - pred_class) * (1 - target_class)).sum().item()\n",
    "        \n",
    "        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        print(f\"  Class {class_idx:2d}: P={precision:.3f}, R={recall:.3f}, F1={f1:.3f}, \"\n",
    "              f\"TP={true_positives:3.0f}, FP={false_positives:3.0f}, FN={false_negatives:3.0f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # 1. Load the trained model\n",
    "    checkpoint_path = './checkpoints/dfb_2025-05-28_13-27-01/final_model.pth'  # Update this path\n",
    "    model = load_model(checkpoint_path, device)\n",
    "    \n",
    "    # 2. Load test dataset\n",
    "    dataset = TopicDataset(\n",
    "        genome='data/resources/mm10.fa',\n",
    "        region_topic_bed='data/Furlanis_Topics_top_3k/regions_and_topics_sorted.bed',\n",
    "        transform=None,\n",
    "        target_transform=None\n",
    "    )\n",
    "    \n",
    "    # 3. Create test split (same as training)\n",
    "    torch.manual_seed(42)  # Same seed as training for consistent split\n",
    "    train_size = int(0.7 * len(dataset))\n",
    "    val_size = int(0.15 * len(dataset))\n",
    "    test_size = len(dataset) - val_size - train_size\n",
    "    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "    \n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=1)\n",
    "    \n",
    "    print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "    \n",
    "    # 4. Test single sample\n",
    "    print(\"\\n=== SINGLE SAMPLE TEST ===\")\n",
    "    sample = test_dataset[0]\n",
    "    result = test_single_sample(model, sample, device)\n",
    "    \n",
    "    print(f\"Sample sequence shape: {result['sequence_shape']}\")\n",
    "    print(f\"True labels: {result['true_label']}\")\n",
    "    print(f\"Predicted probabilities: {result['pred_probs']}\")\n",
    "    print(f\"Predicted binary (>0.5): {result['pred_binary']}\")\n",
    "    print(f\"Number of true positives: {result['true_label'].sum()}\")\n",
    "    print(f\"Number of predicted positives: {result['pred_binary'].sum()}\")\n",
    "    \n",
    "    # 5. Comprehensive testing\n",
    "    print(\"\\n=== COMPREHENSIVE TESTING ===\")\n",
    "    results, all_probs, all_targets, all_predictions = test_model_comprehensive(model, test_dataloader, device)\n",
    "    \n",
    "    # 6. Print results for all thresholds\n",
    "    print(\"\\nResults across different thresholds:\")\n",
    "    print(\"Thresh | Exact  | Hamming| Jaccard|  F1   | Pred/Target\")\n",
    "    print(\"-------|--------|--------|--------|-------|------------\")\n",
    "    for threshold, metrics in results.items():\n",
    "        print(f\"{threshold:6.2f} | {metrics['exact_match']:6.4f} | {metrics['hamming_acc']:6.4f} | \"\n",
    "              f\"{metrics['jaccard_acc']:6.4f} | {metrics['avg_f1']:5.3f} | \"\n",
    "              f\"{metrics['pred_ratio']:6.2f}\")\n",
    "    \n",
    "    # 7. Find best threshold\n",
    "    best_threshold = max(results.keys(), key=lambda x: results[x]['exact_match'])\n",
    "    print(f\"\\nBest threshold for exact match: {best_threshold} \"\n",
    "          f\"(Exact Match: {results[best_threshold]['exact_match']:.4f})\")\n",
    "    \n",
    "    # 8. Detailed analysis at best threshold\n",
    "    analyze_predictions(all_probs, all_targets, threshold=best_threshold)\n",
    "    \n",
    "    # 9. Test on specific examples\n",
    "    print(\"\\n=== SPECIFIC EXAMPLE ANALYSIS ===\")\n",
    "    for i in range(min(5, len(test_dataset))):\n",
    "        sample = test_dataset[i]\n",
    "        result = test_single_sample(model, sample, device)\n",
    "        print(f\"\\nSample {i}:\")\n",
    "        print(f\"  True positives: {result['true_label'].sum():.0f}\")\n",
    "        print(f\"  Pred positives: {result['pred_binary'].sum():.0f}\")\n",
    "        print(f\"  Max prob: {result['pred_probs'].max():.3f}\")\n",
    "        print(f\"  Min prob: {result['pred_probs'].min():.3f}\")\n",
    "        print(f\"  Exact match: {(result['pred_binary'] == result['true_label']).all()}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
